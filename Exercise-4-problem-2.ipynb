{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Calculate and visualize the dominance areas of shopping centers (10 points)\n",
    "\n",
    "In this problem, the aim is to define the dominance area for each of those shopping centers based on public transport travel time. The result will look something like this:\n",
    "\n",
    "![](img/P2_sample.png)\n",
    "\n",
    "\n",
    "### Data\n",
    "\n",
    " - The [data/](data/) directory contains 7 text files having data about accessibility in Helsinki Region, and a Shapefile that contains a Polygon grid that can be used to visualize and analyze the data spatially:\n",
    " \n",
    "     - `travel_times_to_[XXXXXXX]_[NAME-OF-THE-CENTER].txt` including travel times and road network distances to a specific shopping center\n",
    "     - `MetropAccess_YKR_grid_EurefFIN.shp` including the Polygon grid with YKR_ID column that can be used to join the grid with the    accessibility data\n",
    "\n",
    "\n",
    "### An overview of the problem\n",
    "\n",
    "In this problem we want to identify the closest shopping center for each grid cell in the region by public transport, and to visualize dominance areas for each shopping center based on this information. \n",
    "\n",
    "1. **Combine public transport travel time information from all input files into one GeoDataFrame**. \n",
    "    - Read in the grid file (`MetropAccess_YKR_grid_EurefFIN.shp`)\n",
    "    - For each travel time file (7 files in total):\n",
    "         - read in the data\n",
    "         - rename the travel time columns so that they can be identified; Include the name of each shopping center to the column name: `'pt_r_t_Jumbo', 'pt_r_t_Dixi'`, and so on, based on the input file name.\n",
    "         - Join those columns into the grid where `YKR_ID` in the grid corresponds to `from_id` in the travel time data file. \n",
    "    - At the end you should have one GeoDataFrame with different columns containing the travel times to different shopping centers.\n",
    "     \n",
    "     \n",
    "2. **Find out the closes shopping center for each grid cell in the region**:\n",
    "    - For each grid cell (each row) find out the **minimum time** across **all** travel time columns (`pt_r_t_X`) and insert that value into a new column called `min_t`. \n",
    "    - You should also figure out the name of the shopping center that is closest to that particular grid square and store the name of the closest shopping center into a new column `dominant_service` on each row. \n",
    "        - Hint: You can identify which column contains the minimum travel time on each row using the `idxmin()` function.\n",
    "    \n",
    "    \n",
    "3. **Finally, visualize the dominance areas and travel times**:\n",
    "     - visualize the dominance areas using the codes found in column `dominant_service`. \n",
    "     - Visualize travel times to shopping centers from the `min_t` column \n",
    "     - You should create subplots with 2 rows and one column (see the example above).\n",
    "     \n",
    "In this way, we are able to determine the \"closest\" shopping center for each grid cell and visualize the dominance area for each shopping center (by visualizing the grid squares according to the dominant service), or the travel time from each grid cell to the closest shopping center (see example figure above). Remember to upload all your work into your own Exercise 4 repository.\n",
    " \n",
    "### Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read `MetropAccess_YKR_grid_EurefFIN.shp` shapefile into a variable called `grid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85d6d019e5a3ab02634814ca30c19990",
     "grade": false,
     "grade_id": "read_filepaths",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "grid = gpd.read_file(\"data/MetropAccess_YKR_grid_EurefFIN.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c823e5f4a607446412b2bfb8a8cac8a",
     "grade": true,
     "grade_id": "problem_2_read_filepaths_test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x          y   YKR_ID  \\\n",
      "0  381875.0  6697880.0  5785640   \n",
      "1  382125.0  6697880.0  5785641   \n",
      "2  382375.0  6697880.0  5785642   \n",
      "3  382625.0  6697880.0  5785643   \n",
      "4  381125.0  6697630.0  5787544   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((382000.000 6697750.000, 381750.000 6...  \n",
      "1  POLYGON ((382250.000 6697750.000, 382000.000 6...  \n",
      "2  POLYGON ((382500.000 6697750.000, 382250.000 6...  \n",
      "3  POLYGON ((382750.000 6697750.000, 382500.000 6...  \n",
      "4  POLYGON ((381250.000 6697500.000, 381000.000 6...  \n"
     ]
    }
   ],
   "source": [
    "# NON-EDITABLE TEST CELL\n",
    "#Check input grid\n",
    "print(grid.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fetch the filepaths to all textfiles found in [data/](/data) directory that contain information about the travel times to different shopping centers\n",
    "  - Use `glob.glob()` -function to list the filenames into a list called `filepaths`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75023ac7682c11ca65ffa9034375ddd5",
     "grade": false,
     "grade_id": "cell-fd299c5ebdc26382",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\TravelTimes_to_5878070_Jumbo.txt',\n",
       " 'data\\\\TravelTimes_to_5878087_Dixi.txt',\n",
       " 'data\\\\TravelTimes_to_5902043_Myyrmanni.txt',\n",
       " 'data\\\\TravelTimes_to_5944003_Itis.txt',\n",
       " 'data\\\\TravelTimes_to_5975373_Forum.txt',\n",
       " 'data\\\\TravelTimes_to_5978593_IsoOmena.txt',\n",
       " 'data\\\\TravelTimes_to_5980260_Ruoholahti.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "filepaths = glob.glob(\"data/T*.txt\") #*は正規表現と呼ばれる。TravelTimesが共通しているファイルのファイルパスを全て取り出している。\n",
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "866746cdcf09073e28a61d953d627f0b",
     "grade": true,
     "grade_id": "problem_2_glob_test",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of travel time data files:  7\n"
     ]
    }
   ],
   "source": [
    "# NON-EDITABLE TEST CELL\n",
    "# Check how many filepaths there are\n",
    "print(\"Number of travel time data files: \", len(filepaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join information from all the input layers into the grid.** As output, you should have a GeoDataFrame (`grid`)\n",
    "that contains the YKR_ID, grid geometry, and travel times to each shopping center. You should have (at least) 9 columns in the merged output:\n",
    "\n",
    "Required columns: `'YKR_ID', 'pt_r_t_Jumbo', 'pt_r_t_Dixi', 'pt_r_t_Myyrmanni', 'pt_r_t_Itis', 'pt_r_t_Forum', 'pt_r_t_IsoOmena', 'pt_r_t_Ruoholahti', 'geometry'`.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "Create a for-loop where you iterate over the `filepaths` list:\n",
    "\n",
    "  - Read the current filepath using pandas \n",
    "  - Select columns `from_id` and `pt_r_t` from the data (= subset the data so that it only contains these columns)\n",
    "  - Rename column `from_id` to `YKR_ID` (this makes the join easier)\n",
    "  - Rename the column `pt_r_t` in a way that it has contains the shopping center name. On first iteration the column name should be `pt_r_t_Jumbo`, on the second iteration `pt_r_t_Dixi` and so on.\n",
    "  - Make a table join between the `grid` GeoDataFrame and the travel times (with updated column name) using the `merge()` function (at each iteration, you add a new column to variable `grid`). Do the join based on the `YKR_ID` column.\n",
    "  \n",
    "*How to get the shopping center name?*\n",
    "\n",
    "- You can split the input filepath based on the underscores (`\"_\"`) using the [str.split](https://docs.python.org/3.7/library/stdtypes.html#str.split) function. The shopping center name is the last object (located at index -1) in the splitted object.\n",
    "- Furthermore, you can strip out letters from the string object using string slicing. For example, if `fp = \"redi.txt\"`, then `fp[:-4]` equals to \"redi\" :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f798cb4d7e7571d731058d80cbf71057",
     "grade": false,
     "grade_id": "merge_traveltimes",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>YKR_ID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>pt_r_t_Jumbo</th>\n",
       "      <th>pt_r_t_Dixi</th>\n",
       "      <th>pt_r_t_Myyrmanni</th>\n",
       "      <th>pt_r_t_Itis</th>\n",
       "      <th>pt_r_t_Forum</th>\n",
       "      <th>pt_r_t_IsoOmena</th>\n",
       "      <th>pt_r_t_Ruoholahti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381875.0</td>\n",
       "      <td>6697880.0</td>\n",
       "      <td>5785640</td>\n",
       "      <td>POLYGON ((382000.000 6697750.000, 381750.000 6...</td>\n",
       "      <td>101</td>\n",
       "      <td>102</td>\n",
       "      <td>90</td>\n",
       "      <td>132</td>\n",
       "      <td>110</td>\n",
       "      <td>141</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382125.0</td>\n",
       "      <td>6697880.0</td>\n",
       "      <td>5785641</td>\n",
       "      <td>POLYGON ((382250.000 6697750.000, 382000.000 6...</td>\n",
       "      <td>108</td>\n",
       "      <td>109</td>\n",
       "      <td>93</td>\n",
       "      <td>135</td>\n",
       "      <td>113</td>\n",
       "      <td>143</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>382375.0</td>\n",
       "      <td>6697880.0</td>\n",
       "      <td>5785642</td>\n",
       "      <td>POLYGON ((382500.000 6697750.000, 382250.000 6...</td>\n",
       "      <td>109</td>\n",
       "      <td>111</td>\n",
       "      <td>95</td>\n",
       "      <td>137</td>\n",
       "      <td>115</td>\n",
       "      <td>145</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>382625.0</td>\n",
       "      <td>6697880.0</td>\n",
       "      <td>5785643</td>\n",
       "      <td>POLYGON ((382750.000 6697750.000, 382500.000 6...</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>99</td>\n",
       "      <td>141</td>\n",
       "      <td>119</td>\n",
       "      <td>149</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>381125.0</td>\n",
       "      <td>6697630.0</td>\n",
       "      <td>5787544</td>\n",
       "      <td>POLYGON ((381250.000 6697500.000, 381000.000 6...</td>\n",
       "      <td>98</td>\n",
       "      <td>99</td>\n",
       "      <td>83</td>\n",
       "      <td>125</td>\n",
       "      <td>103</td>\n",
       "      <td>134</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13226</th>\n",
       "      <td>372875.0</td>\n",
       "      <td>6665630.0</td>\n",
       "      <td>6016698</td>\n",
       "      <td>POLYGON ((373000.000 6665500.000, 372750.000 6...</td>\n",
       "      <td>109</td>\n",
       "      <td>79</td>\n",
       "      <td>95</td>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>38</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>373125.0</td>\n",
       "      <td>6665630.0</td>\n",
       "      <td>6016699</td>\n",
       "      <td>POLYGON ((373250.000 6665500.000, 373000.000 6...</td>\n",
       "      <td>110</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>81</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>372375.0</td>\n",
       "      <td>6665380.0</td>\n",
       "      <td>6018252</td>\n",
       "      <td>POLYGON ((372500.000 6665250.000, 372250.000 6...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>372625.0</td>\n",
       "      <td>6665380.0</td>\n",
       "      <td>6018253</td>\n",
       "      <td>POLYGON ((372750.000 6665250.000, 372500.000 6...</td>\n",
       "      <td>114</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>57</td>\n",
       "      <td>43</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13230</th>\n",
       "      <td>372875.0</td>\n",
       "      <td>6665380.0</td>\n",
       "      <td>6018254</td>\n",
       "      <td>POLYGON ((373000.000 6665250.000, 372750.000 6...</td>\n",
       "      <td>112</td>\n",
       "      <td>83</td>\n",
       "      <td>98</td>\n",
       "      <td>83</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13231 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x          y   YKR_ID  \\\n",
       "0      381875.0  6697880.0  5785640   \n",
       "1      382125.0  6697880.0  5785641   \n",
       "2      382375.0  6697880.0  5785642   \n",
       "3      382625.0  6697880.0  5785643   \n",
       "4      381125.0  6697630.0  5787544   \n",
       "...         ...        ...      ...   \n",
       "13226  372875.0  6665630.0  6016698   \n",
       "13227  373125.0  6665630.0  6016699   \n",
       "13228  372375.0  6665380.0  6018252   \n",
       "13229  372625.0  6665380.0  6018253   \n",
       "13230  372875.0  6665380.0  6018254   \n",
       "\n",
       "                                                geometry  pt_r_t_Jumbo  \\\n",
       "0      POLYGON ((382000.000 6697750.000, 381750.000 6...           101   \n",
       "1      POLYGON ((382250.000 6697750.000, 382000.000 6...           108   \n",
       "2      POLYGON ((382500.000 6697750.000, 382250.000 6...           109   \n",
       "3      POLYGON ((382750.000 6697750.000, 382500.000 6...           114   \n",
       "4      POLYGON ((381250.000 6697500.000, 381000.000 6...            98   \n",
       "...                                                  ...           ...   \n",
       "13226  POLYGON ((373000.000 6665500.000, 372750.000 6...           109   \n",
       "13227  POLYGON ((373250.000 6665500.000, 373000.000 6...           110   \n",
       "13228  POLYGON ((372500.000 6665250.000, 372250.000 6...            -1   \n",
       "13229  POLYGON ((372750.000 6665250.000, 372500.000 6...           114   \n",
       "13230  POLYGON ((373000.000 6665250.000, 372750.000 6...           112   \n",
       "\n",
       "       pt_r_t_Dixi  pt_r_t_Myyrmanni  pt_r_t_Itis  pt_r_t_Forum  \\\n",
       "0              102                90          132           110   \n",
       "1              109                93          135           113   \n",
       "2              111                95          137           115   \n",
       "3              115                99          141           119   \n",
       "4               99                83          125           103   \n",
       "...            ...               ...          ...           ...   \n",
       "13226           79                95           79            52   \n",
       "13227           81                97           81            54   \n",
       "13228           -1                -1           -1            -1   \n",
       "13229           84               100           84            57   \n",
       "13230           83                98           83            55   \n",
       "\n",
       "       pt_r_t_IsoOmena  pt_r_t_Ruoholahti  \n",
       "0                  141                118  \n",
       "1                  143                121  \n",
       "2                  145                123  \n",
       "3                  149                127  \n",
       "4                  134                111  \n",
       "...                ...                ...  \n",
       "13226               38                 48  \n",
       "13227               40                 50  \n",
       "13228               -1                 -1  \n",
       "13229               43                 53  \n",
       "13230               42                 52  \n",
       "\n",
       "[13231 rows x 11 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for path in filepaths:\n",
    "    data = pd.read_csv(path, sep=';')\n",
    "    data = data[['from_id', 'pt_r_t']]\n",
    "    shop_name = path.split('_')[-1]\n",
    "    shop_name = shop_name[:-4]\n",
    "    data = data.rename(columns={'from_id':'YKR_ID', 'pt_r_t':'pt_r_t_{}'.format(shop_name)})\n",
    "    grid = grid.merge(data)\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b4962547b0f513988d098e161d13ba1",
     "grade": true,
     "grade_id": "problem_2_merge_traveltimes_tests",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x          y   YKR_ID  \\\n",
      "0  381875.0  6697880.0  5785640   \n",
      "1  382125.0  6697880.0  5785641   \n",
      "2  382375.0  6697880.0  5785642   \n",
      "3  382625.0  6697880.0  5785643   \n",
      "4  381125.0  6697630.0  5787544   \n",
      "\n",
      "                                            geometry  pt_r_t_Jumbo  \\\n",
      "0  POLYGON ((382000.000 6697750.000, 381750.000 6...           101   \n",
      "1  POLYGON ((382250.000 6697750.000, 382000.000 6...           108   \n",
      "2  POLYGON ((382500.000 6697750.000, 382250.000 6...           109   \n",
      "3  POLYGON ((382750.000 6697750.000, 382500.000 6...           114   \n",
      "4  POLYGON ((381250.000 6697500.000, 381000.000 6...            98   \n",
      "\n",
      "   pt_r_t_Dixi  pt_r_t_Myyrmanni  pt_r_t_Itis  pt_r_t_Forum  pt_r_t_IsoOmena  \\\n",
      "0          102                90          132           110              141   \n",
      "1          109                93          135           113              143   \n",
      "2          111                95          137           115              145   \n",
      "3          115                99          141           119              149   \n",
      "4           99                83          125           103              134   \n",
      "\n",
      "   pt_r_t_Ruoholahti  \n",
      "0                118  \n",
      "1                121  \n",
      "2                123  \n",
      "3                127  \n",
      "4                111  \n"
     ]
    }
   ],
   "source": [
    "# NON-EDITABLE TEST CELL\n",
    "#Check data\n",
    "print(grid.head())\n",
    "\n",
    "# Check that there are correct number of columns\n",
    "assert len(grid.columns) >= 9, \"There are some columns missing from the grid.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove rows containing -1 (no data values) from the dataframe. You can for example replace the no-data values with numpy's `np.nan`, and then drop no-data values using the [DataFrame.dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16839d6c52be4c83c397a0d2e00cffc3",
     "grade": false,
     "grade_id": "no_data",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "grid = grid.replace(-1, np.nan)\n",
    "grid = grid.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each grid cell (each row), find out the shortest travel time to any shopping center. Store the result in a new column `'min_t'`.\n",
    "- Find out also the column name (for example: `'pt_r_t_Jumbo'`), for the shortest travel time using the `idxmin()` function into a column called `'dominant_service'` ([see hints](https://automating-gis-processes.github.io/site/develop/lessons/L4/exercise-4.html#finding-out-which-shopping-center-is-the-closest)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0560afabf1989b7fa98862b2b0b8af70",
     "grade": false,
     "grade_id": "min_t",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "columns = [\"pt_r_t_Jumbo\", \"pt_r_t_Dixi\", \"pt_r_t_Myyrmanni\", \"pt_r_t_Itis\", \"pt_r_t_Forum\", \"pt_r_t_IsoOmena\", \"pt_r_t_Ruoholahti\"]\n",
    "# Create a new column for minimum travel time values \n",
    "grid['min_t']=None\n",
    "grid['dominant_service']=None\n",
    "\n",
    "for index, row in grid.iterrows(): #インデックス名と値の両方を取り出す必要がある。使わないにしても \n",
    "    minimum_values = row[columns].min() #行列に対するmin()は各列についての最小値\n",
    "    closest_shop = row[columns].astype('float16').idxmin() #idxmin()は最小値を取るインデックスを返してくれる。\n",
    "    grid[index, 'min_t'] = minimum_values\n",
    "    grid[index, 'dominant_service'] = closest_shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c98db9c7e4a063ff7696526350087958",
     "grade": true,
     "grade_id": "problem_2_min_t_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['YKR_ID', 'min_t', 'dominant_service'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-7ae0d178c18c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# NON-EDITABLE TEST CELL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'YKR_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dominant_service'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['YKR_ID', 'min_t', 'dominant_service'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# NON-EDITABLE TEST CELL\n",
    "print(grid[['YKR_ID', 'min_t', 'dominant_service']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2998ea638518cf02cad0bfa1930f9018",
     "grade": true,
     "grade_id": "problem_2_dominant_service_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        YKR_ID min_t dominant_service\n",
      "13225  6016697  None             None\n",
      "13226  6016698  None             None\n",
      "13227  6016699  None             None\n",
      "13229  6018253  None             None\n",
      "13230  6018254  None             None\n"
     ]
    }
   ],
   "source": [
    "# NON-EDITABLE TEST CELL\n",
    "print(grid[['YKR_ID', 'min_t', 'dominant_service']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualize the dominance areas and travel times in one figure which has 2 subplots (2 rows and one column):\n",
    "     - visualize the dominance areas using the names found in `dominant_service` column. \n",
    "     - Visualize travel times to shopping centers from the `min_t` column \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28c4c267871440bad21089a47127d542",
     "grade": true,
     "grade_id": "plot",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make subplots that are next to each other\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "grid.plot(column='dominant_service', cmap=\"RdYlBu\", ax=ax1)\n",
    "\n",
    "# Add title\n",
    "ax1.set_title(\"dominant_service\")\n",
    "\n",
    "# Plot the one with ETRS-LAEA projection\n",
    "grid.plot(column='min_t', cmap=\"RdYlBu\", ax=ax2)\n",
    "\n",
    "# Add title\n",
    "ax2.set_title(\"min_t\")\n",
    "\n",
    "# Set aspect ratio as 1\n",
    "ax1.set_aspect(aspect=1)\n",
    "ax2.set_aspect(aspect=1)\n",
    "\n",
    "# Remove empty white space around the plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! If you want more challenge, you can still continue to optional problem 3. For problem 3, you need to save the `grid` with information about dominant services to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save grid to file (if you want to continue to problem 3)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
